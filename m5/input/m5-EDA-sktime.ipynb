{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](p2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the \"M5 Forecasting - Accuracy\" competition! In this competition, contestants are challenged to forecast future sales at Walmart based on heirarchical sales in the states of California, Texas, and Wisconsin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Goal\n",
    "\n",
    "The objective of the task is to find he **most accurate point forecasts** for each of the 42,840 time series of the competition. \n",
    "\n",
    "The time series are shown below -\n",
    "\n",
    "![title](p3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset <a id=\"1\"></a>\n",
    "\n",
    "The M5 dataset, generously made available by Walmart, involves the unit sales of various products sold in the USA, organized in the form of grouped time series. More specifically, the dataset involves the unit sales of 3,049 products, classified in 3 product categories (Hobbies, Foods, and Household) and 7 product departments, in which the above-mentioned categories are disaggregated.  The products are sold across ten stores, located in three States (CA, TX, and WI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The dataset consists of five .csv files.\n",
    "\n",
    "* <code>calendar.csv</code> - Contains the dates on which products are sold. The dates are in a <code>yyyy/dd/mm</code> format.\n",
    "\n",
    "* <code>sales_train_validation.csv</code> - Contains the historical daily unit sales data per product and store <code>[d_1 - d_1913]</code>.\n",
    "\n",
    "* <code>submission.csv</code> - Demonstrates the correct format for submission to the competition.\n",
    "\n",
    "* <code>sell_prices.csv</code> - Contains information about the price of the products sold per store and date.\n",
    "\n",
    "* <code>sales_train_evaluation.csv</code> - Available one month before the competition deadline. It will include sales for <code>[d_1 - d_1941]</code>.\n",
    "\n",
    "In this competition, we need to forecast the sales for <code>[d_1942 - d_1969]</code>. These rows form the evaluation set. The rows <code>[d_1914 - d_1941]</code> form the validation set, and the remaining rows form the training set. Now, since we understand the dataset and know what to predict, let us visualize the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "from math import log, floor\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "#from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "\n",
    "import scipy\n",
    "import statsmodels\n",
    "from scipy import signal\n",
    "import statsmodels.api as sm\n",
    "from fbprophet import Prophet\n",
    "from scipy.signal import butter, deconvolve\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import pywt\n",
    "from statsmodels.robust import mad\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../input/m5-forecasting-accuracy'\n",
    "calendar = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\n",
    "selling_prices = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')\n",
    "sample_submission = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\n",
    "sales_train_val = pd.read_csv(f'{INPUT_DIR}/sales_train_validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider 3 time series here, that is the unit sale of item X in a specific store, here we choose:\n",
    "\n",
    "1. FOODS_3_388_CA_1_validation\n",
    "2. HOBBIES_2_148_CA_1_validation\n",
    "3. HOUSEHOLD_2_468_CA_1_validation\n",
    "\n",
    "Corresponding to id 10k,20k and 30k respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = sorted(list(set(sales_train_val['id'])))\n",
    "d_cols = [c for c in sales_train_val.columns if 'd_' in c]\n",
    "x_1 = sales_train_val.loc[sales_train_val['id'] == ids[10000]].set_index('id')[d_cols].values[0]\n",
    "x_2 = sales_train_val.loc[sales_train_val['id'] == ids[20000]].set_index('id')[d_cols].values[0]\n",
    "x_3 = sales_train_val.loc[sales_train_val['id'] == ids[30000]].set_index('id')[d_cols].values[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising a part of Sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(x_1)), y=x_1,),\n",
    "             row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(x_2)), y=x_2,),\n",
    "             row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(x_3)), y=x_3,),\n",
    "             row=3, col=1)\n",
    "\n",
    "fig.update_layout(height=1200, width=800, title_text=\"Sample sales\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_smoothing(signal, kernel_size=3, stride=1):\n",
    "    sample = []\n",
    "    start = 0\n",
    "    end = kernel_size\n",
    "    while end <= len(signal):\n",
    "        start = start + stride\n",
    "        end = end + stride\n",
    "        sample.extend(np.ones(end - start)*np.mean(signal[start:end]))\n",
    "    return np.array(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_a1 = average_smoothing(x_1)\n",
    "y_a2 = average_smoothing(x_2)\n",
    "y_a3 = average_smoothing(x_3)\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(x_1)), mode='lines+markers', y=x_1, marker=dict(color=\"lightskyblue\"), showlegend=False,\n",
    "               name=\"Original sales\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(x_1)), y=y_a1, mode='lines', marker=dict(color=\"navy\"), showlegend=False,\n",
    "               name=\"Denoised sales\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(x_2)), mode='lines+markers', y=x_2, marker=dict(color=\"thistle\"), showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(x_2)), y=y_a2, mode='lines', marker=dict(color=\"indigo\"), showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(x_3)), mode='lines+markers', y=x_3, marker=dict(color=\"mediumaquamarine\"), showlegend=False),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(len(x_3)), y=y_a3, mode='lines', marker=dict(color=\"darkgreen\"), showlegend=False),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=1200, width=800, title_text=\"Original (pale) vs. Denoised (dark) signals\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling Average Sales with Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "past_sales = sales_train_val.set_index('id')[d_cols] \\\n",
    "    .T \\\n",
    "    .merge(calendar.set_index('d')['date'],\n",
    "           left_index=True,\n",
    "           right_index=True,\n",
    "            validate='1:1') \\\n",
    "    .set_index('date')\n",
    "\n",
    "store_list = selling_prices['store_id'].unique()\n",
    "means = []\n",
    "fig = go.Figure()\n",
    "for s in store_list:\n",
    "    store_items = [c for c in past_sales.columns if s in c]\n",
    "    data = past_sales[store_items].sum(axis=1).rolling(90).mean()\n",
    "    means.append(np.mean(past_sales[store_items].sum(axis=1)))\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(data)), y=data, name=s))\n",
    "    \n",
    "fig.update_layout(yaxis_title=\"Sales\", xaxis_title=\"Time\", title=\"Rolling Average Sales vs. Time (per store)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling a part of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pmdarima\n",
    "!pip install sktime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.performance_metrics.forecasting import smape_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall = sales_train_val.sum(axis=0,skipna=True,numeric_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overall1 = pd.Series(pd.Series.to_numpy(Overall)[-500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = temporal_train_test_split(Overall1, test_size=50)\n",
    "print(y_train.shape[0], y_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = np.arange(50)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450), mode='lines', y=y_train.values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n",
    "               name=\"Original signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_test.values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive approach <a id=\"3.2\"></a>\n",
    "\n",
    "It simply forecasts the next day's sales as the current day's sales. The model can be summarized as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/r8wjrzk.png\" width=\"110px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = NaiveForecaster(strategy=\"last\")\n",
    "forecaster.fit(y_train)\n",
    "y_last = forecaster.predict(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450), mode='lines', y=y_train.values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n",
    "               name=\"Original signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_test.values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_last.values, mode='lines', marker=dict(color=\"green\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dynamic Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = NaiveForecaster(strategy=\"last\")\n",
    "forecaster.fit(y_train)\n",
    "from sktime.forecasting.model_selection import SlidingWindowSplitter\n",
    "cv = SlidingWindowSplitter(fh=1)\n",
    "y_pred = forecaster.update_predict(y_test, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_test.values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_pred.values, mode='lines', marker=dict(color=\"green\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential smoothing <a id=\"3.5\"></a>\n",
    "\n",
    "The **exponential smoothing** method uses a different type of smoothing which differs from average smoothing. The previous time steps are exponentially weighted and added up to generate the forecast. The weights decay as we move further backwards in time. The model can be summarized as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/IqqjOFc.png\" width=\"520px\">\n",
    "<img src=\"https://i.imgur.com/GiyHyZf.png\" width=\"255px\">\n",
    "\n",
    "In the above equations, $\\alpha$ is the smoothing parameter. The forecast *y<sub>t+1</sub>* is a weighted average of all the observations in the series *y<sub>1</sub>, … ,y<sub>t</sub>*. The rate at which the weights decay is controlled by the parameter *α*. This method gives different weightage to different time steps, instead of giving the same weightage to all time steps (like the moving average method). This ensures that recent sales data is given more importance than old sales data while making the forecast. Now let us see how this new smoothing method performs on our miniature dataset. The training data is in <font color=\"blue\">blue</font>, validation data in <font color=\"darkorange\">orange</font>, and predictions in <font color=\"green\">green</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"multiplicative\", sp=14)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "smape_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(300,450), mode='lines', y=y_train.values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n",
    "               name=\"Original signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_test.values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_pred.values, mode='lines', marker=dict(color=\"green\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA <a id=\"3.6\"></a>\n",
    "\n",
    "**ARIMA** stands for **A**uto **R**egressive **I**ntegrated **M**oving **A**verage. While exponential smoothing models were based on a description of trend and seasonality in data, ARIMA models aim to describe the correlations in the time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "forecaster = AutoARIMA(sp=14, suppress_warnings=True)\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(300,450), mode='lines', y=y_train.values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n",
    "               name=\"Original signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_test.values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_pred.values, mode='lines', marker=dict(color=\"green\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Ensembling\n",
    " we can combine different variants of exponential smoothing as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import EnsembleForecaster\n",
    "forecaster = EnsembleForecaster([\n",
    "    (\"ses\", ExponentialSmoothing(seasonal=\"multiplicative\", sp=14)),\n",
    "    (\"holt\", ExponentialSmoothing(trend=\"add\", damped=False, seasonal=\"multiplicative\", sp=14)),\n",
    "    (\"damped\", ExponentialSmoothing(trend=\"add\", damped=True, seasonal=\"multiplicative\", sp=14))\n",
    "])\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "smape_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(300,450), mode='lines', y=y_train.values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n",
    "               name=\"Original signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_test.values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_pred.values, mode='lines', marker=dict(color=\"green\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detrending\n",
    "\n",
    "We can try to see if the above time series has any long term trends. Let's check for linear trend-\n",
    "\n",
    "We can see below that the trend is small incrementing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformers.single_series.detrend import Detrender\n",
    "\n",
    "# liner detrending\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "transformer = Detrender(forecaster=forecaster)\n",
    "yt = transformer.fit_transform(y_train)\n",
    "\n",
    "# internally, the Detrender uses the in-sample predictions of the PolynomialTrendForecaster\n",
    "forecaster = PolynomialTrendForecaster(degree=1)\n",
    "fh_ins = -np.arange(len(y_train)) # in-sample forecasting horizon\n",
    "y_pred = forecaster.fit(y_train).predict(fh=fh_ins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450), mode='lines', y=y_train.values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n",
    "               name=\"Original signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange( 500), y=y_pred.values, mode='lines', marker=dict(color=\"green\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelining\n",
    "\n",
    "Let's use the detrender in a pipeline together with de-seasonalisation. And finally a regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformers.single_series.detrend import Deseasonalizer\n",
    "from sktime.forecasting.compose import ReducedRegressionForecaster\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "regressor = KNeighborsRegressor(n_neighbors=1)\n",
    "forecaster = TransformedTargetForecaster([\n",
    "    (\"deseasonalise\", Deseasonalizer(model=\"multiplicative\", sp=12)),\n",
    "    (\"detrend\", Detrender(forecaster=PolynomialTrendForecaster(degree=1))),\n",
    "    (\"forecast\", ReducedRegressionForecaster(regressor=regressor, window_length=15, strategy=\"recursive\"))\n",
    "])\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh)\n",
    "smape_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(300,450), mode='lines', y=y_train.values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n",
    "               name=\"Original signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_test.values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(450, 500), y=y_pred.values, mode='lines', marker=dict(color=\"green\"), showlegend=False,\n",
    "               name=\"Denoised signal\"),\n",
    "    row=1, col=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
